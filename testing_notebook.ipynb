{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "from torchvision import transforms, datasets\n",
    "import random\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the tgt_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "with open('data/synset_closest_idx.yaml', 'r') as file:\n",
    "    synset_closest_idx = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "data_path = '/misc/scratchSSD2/datasets/ILSVRC2012/val'\n",
    "out_size = 256\n",
    "transform_list = [\n",
    "    transforms.Resize((out_size,out_size)),\n",
    "    transforms.ToTensor()\n",
    "]\n",
    "transform = transforms.Compose(transform_list)\n",
    "dataset = datasets.ImageFolder(data_path,  transform=transform)\n",
    "\n",
    "idx_image_to_tgt_class = {}\n",
    "for i in range(len(dataset)):\n",
    "    img, label = dataset[i]\n",
    "    #print(synset_closest_idx[label], random.choice(synset_closest_idx[label]))\n",
    "    idx_image_to_tgt_class[i] = random.choice(synset_closest_idx[label])\n",
    "    if i%100==0:\n",
    "        print(f\"current image index: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/image_idx_to_tgt_class_closest_5.yaml', 'w') as file:\n",
    "    documents = yaml.dump(dict(idx_image_to_tgt_class), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the new Imagenet wrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/image_idx_to_tgt_class_closest_5.yaml', 'r') as file:\n",
    "    image_idx_to_tgt_class_closest_5 = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx_to_tgt_class_closest_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagenet_classnames import name_map, folder_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNet(datasets.ImageFolder):\n",
    "    classes = [name_map[i] for i in range(1000)]\n",
    "    name_map = name_map\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            root:str, \n",
    "            split:str=\"val\", \n",
    "            transform=None, \n",
    "            target_transform=None, \n",
    "            class_idcs=None, \n",
    "            start_sample: int = 0, \n",
    "            end_sample: int = 50000//1000,\n",
    "            return_tgt_cls: bool = False,\n",
    "            idx_to_tgt_cls_path = None, \n",
    "            **kwargs\n",
    "    ):\n",
    "        _ = kwargs  # Just for consistency with other datasets.\n",
    "        assert split in [\"train\", \"val\"]\n",
    "        assert start_sample < end_sample and start_sample >= 0 and end_sample <= 50000//1000\n",
    "        path = root if root[-3:] == \"val\" or root[-5:] == \"train\" else os.path.join(root, split)\n",
    "        super().__init__(path, transform=transform, target_transform=target_transform)\n",
    "        \n",
    "        with open(idx_to_tgt_cls_path, 'r') as file:\n",
    "            idx_to_tgt_cls = yaml.safe_load(file)\n",
    "            if isinstance(idx_to_tgt_cls, dict):\n",
    "                idx_to_tgt_cls = [idx_to_tgt_cls[i] for i in range(len(idx_to_tgt_cls))]\n",
    "        self.idx_to_tgt_cls = idx_to_tgt_cls\n",
    "\n",
    "        self.return_tgt_cls = return_tgt_cls\n",
    "\n",
    "        if class_idcs is not None:\n",
    "            class_idcs = list(sorted(class_idcs))\n",
    "            tgt_to_tgt_map = {c: i for i, c in enumerate(class_idcs)}\n",
    "            self.classes = [self.classes[c] for c in class_idcs]\n",
    "            samples = []\n",
    "            idx_to_tgt_cls = []\n",
    "            for i, (p, t) in enumerate(self.samples):\n",
    "                if t in tgt_to_tgt_map:\n",
    "                    samples.append((p, tgt_to_tgt_map[t]))\n",
    "                    idx_to_tgt_cls.append(self.idx_to_tgt_cls[i])\n",
    "            \n",
    "            self.idx_to_tgt_cls = idx_to_tgt_cls\n",
    "            #self.samples = [(p, tgt_to_tgt_map[t]) for i, (p, t) in enumerate(self.samples) if t in tgt_to_tgt_map]\n",
    "            self.class_to_idx = {k: tgt_to_tgt_map[v] for k, v in self.class_to_idx.items() if v in tgt_to_tgt_map}\n",
    "\n",
    "        if \"val\" == split: # reorder\n",
    "            new_samples = []\n",
    "            idx_to_tgt_cls = []\n",
    "            for idx in range(50000//1000):\n",
    "                new_samples.extend(self.samples[idx::50000//1000])\n",
    "                idx_to_tgt_cls.extend(self.idx_to_tgt_cls[idx::50000//1000])\n",
    "            self.samples = new_samples[start_sample*1000:end_sample*1000]\n",
    "            self.idx_to_tgt_cls = idx_to_tgt_cls[start_sample*1000:end_sample*1000]\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.class_labels = {i: folder_label_map[folder] for i, folder in enumerate(self.classes)}\n",
    "        self.targets = np.array(self.samples)[:, 1]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = super().__getitem__(index)\n",
    "        if self.return_tgt_cls:\n",
    "            return *sample, self.idx_to_tgt_cls[index]\n",
    "        else:\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dict to list \n",
    "image_idx_to_tgt_class_closest_5_list = [ image_idx_to_tgt_class_closest_5[i] for i in range(len(image_idx_to_tgt_class_closest_5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx_to_tgt_class_closest_5_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImageNet('/misc/scratchSSD2/datasets/ILSVRC2012', idx_to_tgt_cls_path='data/image_idx_to_tgt_class_closest_5.yaml', return_tgt_cls = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=500x332>, 3, 389)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_size = 256\n",
    "transform_list = [\n",
    "    transforms.Resize((out_size, out_size)),\n",
    "    transforms.ToTensor()\n",
    "]\n",
    "transform = transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImageNet('/misc/scratchSSD2/datasets/ILSVRC2012', split=\"val\", return_tgt_cls = True, idx_to_tgt_cls=image_idx_to_tgt_class_closest_5_list, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6000, 0.5961, 0.5922,  ..., 0.5412, 0.5294, 0.5176],\n",
       "          [0.5686, 0.5647, 0.5608,  ..., 0.5569, 0.5529, 0.5412],\n",
       "          [0.5333, 0.5255, 0.5294,  ..., 0.5529, 0.5529, 0.5490],\n",
       "          ...,\n",
       "          [0.4980, 0.5333, 0.5804,  ..., 0.1529, 0.2588, 0.2784],\n",
       "          [0.5176, 0.5294, 0.5686,  ..., 0.0353, 0.0275, 0.0431],\n",
       "          [0.5098, 0.5216, 0.5294,  ..., 0.0510, 0.0118, 0.0078]],\n",
       " \n",
       "         [[0.6863, 0.6824, 0.6784,  ..., 0.6627, 0.6510, 0.6392],\n",
       "          [0.6549, 0.6510, 0.6471,  ..., 0.6824, 0.6784, 0.6667],\n",
       "          [0.6196, 0.6118, 0.6157,  ..., 0.6824, 0.6863, 0.6824],\n",
       "          ...,\n",
       "          [0.4549, 0.4902, 0.5373,  ..., 0.1255, 0.2196, 0.2157],\n",
       "          [0.4588, 0.4745, 0.5176,  ..., 0.0235, 0.0235, 0.0353],\n",
       "          [0.4510, 0.4627, 0.4706,  ..., 0.0353, 0.0118, 0.0039]],\n",
       " \n",
       "         [[0.7765, 0.7725, 0.7686,  ..., 0.7333, 0.7255, 0.7137],\n",
       "          [0.7451, 0.7412, 0.7373,  ..., 0.7569, 0.7529, 0.7451],\n",
       "          [0.7098, 0.7020, 0.7059,  ..., 0.7647, 0.7647, 0.7608],\n",
       "          ...,\n",
       "          [0.4353, 0.4588, 0.5059,  ..., 0.1098, 0.1882, 0.1843],\n",
       "          [0.4471, 0.4510, 0.4824,  ..., 0.0196, 0.0235, 0.0353],\n",
       "          [0.4314, 0.4510, 0.4392,  ..., 0.0275, 0.0157, 0.0118]]]),\n",
       " 100,\n",
       " 7)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "ldm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
