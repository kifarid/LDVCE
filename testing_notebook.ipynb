{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "from torchvision import transforms, datasets\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the imagenet graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_node('A')\n",
    "G.add_node('B')\n",
    "G.add_node('C')\n",
    "G.add_node('D')\n",
    "\n",
    "# Add edges\n",
    "G.add_edge('A', 'B')\n",
    "G.add_edge('A', 'C')\n",
    "G.add_edge('B', 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#nx.draw_networkx(G, nx.spring_layout(G))\n",
    "G.remove_node('D')\n",
    "nx.draw_networkx(G, nx.spring_layout(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/imagenette2/synset_human.txt\", \"r\") as f:    \n",
    "    synset_human_complete = f.read().splitlines()\n",
    "    synset_human_complete = dict(line.split(maxsplit=1) for line in synset_human_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagenet_classnames import name_map, folder_label_map\n",
    "\n",
    "synset_human = folder_label_map\n",
    "index_human = name_map\n",
    "\n",
    "#check that synset_human keys are ordered\n",
    "for i, (key_syn, key_index) in enumerate(zip(sorted(synset_human.keys()), sorted(index_human.keys()))):\n",
    "    assert synset_human[key_syn] == index_human[key_index]\n",
    "    assert i == key_index\n",
    "\n",
    "index_synset = { i: k for i, k in enumerate(synset_human.keys())}\n",
    "\n",
    "# validate the index_synset with index to human\n",
    "for index in index_synset.keys():\n",
    "    assert index_human[index] == synset_human[index_synset[index]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wordnet.is_a.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "#convert from synset to human and save to file\n",
    "with open('data/wordnet.is_a_human.txt', 'w') as f:\n",
    "    for line in data.splitlines():\n",
    "        synset1, synset2 = line.split()\n",
    "        f.write(f'{synset_human_complete[synset2]} is a {synset_human_complete[synset1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty directed graph object\n",
    "G_hum = nx.DiGraph()\n",
    "G_syn = nx.DiGraph()\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open('data/wordnet.is_a.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Split the data into lines and iterate over each line\n",
    "for line in data.split('\\n'):\n",
    "    # Split the line into parent and child node IDs\n",
    "    if len(line) > 0:\n",
    "        parent, child = line.split()\n",
    "        if parent in synset_human: \n",
    "            #print(\"parent is a leaf in imagenet\", parent, synset_human[parent], '\\n')\n",
    "            #print(\"the child is\", child, synset_human_complete[child], '\\n')\n",
    "            assert child not in synset_human, \"child is in imagenet\"\n",
    "            continue\n",
    "        # Add an edge between the parent and child nodes\n",
    "        G_hum.add_edge(synset_human_complete[parent], synset_human_complete[child])\n",
    "        G_syn.add_edge(parent, child)\n",
    "\n",
    "# Print the nodes and edges in the graph\n",
    "print(\"Nodes:\", sorted(G_syn.nodes()))\n",
    "print(sorted(synset_human.keys()))\n",
    "#print(\"Edges:\", G1.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(synset_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get duplicated human labels\n",
    "from collections import Counter\n",
    "duplicates = [k for k,v in Counter(synset_human.values()).items() if v>1]\n",
    "duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in synset_human.keys():\n",
    "    assert key in G_syn.nodes(), \"key is in imagenet but not in graph\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #remove the leaf nodes that are not in imagenet\n",
    "# for node in list(G1.nodes):\n",
    "#     if node not in human_synset and G1.out_degree(node) == 0:\n",
    "#         if node == \"volleyball player\":\n",
    "#             print(\"removing\", node, '\\n')\n",
    "#         G1.remove_node(node)\n",
    "\n",
    "# for node in list(G2.nodes):\n",
    "#     if node not in human_synset and G2.out_degree(node) == 0:\n",
    "#         G2.remove_node(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursively remove the leaf nodes that are not in imagenet\n",
    "def remove_leaf_nodes(G):\n",
    "    len_before = len(G.nodes())\n",
    "    for node in list(G.nodes()):\n",
    "        if G.out_degree(node) == 0 and node not in synset_human.values():\n",
    "            G.remove_node(node)\n",
    "            #print(\"removing node\", node)\n",
    "    len_after = len(G.nodes())\n",
    "    print(\"len before\", len_before, \"len after\", len_after)\n",
    "    \n",
    "    if len_before != len_after:\n",
    "        remove_leaf_nodes(G)\n",
    "    return G\n",
    "\n",
    "#recursively remove the leaf nodes that are not in imagenet\n",
    "def remove_leaf_node_syn(G):\n",
    "    len_before = len(G.nodes())\n",
    "    nodes_in_imagenet = [node for node in G.nodes() if node in synset_human]\n",
    "    nodes_not_in_imagenet = [node for node in G.nodes() if node not in synset_human]\n",
    "    total_nodes = len(nodes_in_imagenet)\n",
    "    print(\"total nodes in imagenet\", total_nodes)\n",
    "    print(\"nodes in imagenet\", len(nodes_in_imagenet))\n",
    "    for node in nodes_not_in_imagenet:\n",
    "        if G.out_degree(node) == 0:\n",
    "            G.remove_node(node)\n",
    "            #print(\"removing node\", node)\n",
    "    # for node in list(G.nodes()):\n",
    "\n",
    "    #     if G.out_degree(node) == 0 and node not in synset_human:\n",
    "    #         #print(\"removing node\", node, synset_human[node])\n",
    "    #         G.remove_node(node)\n",
    "    #         #print(\"removing node\", node)\n",
    "    len_after = len(G.nodes())\n",
    "    print(\"len before\", len_before, \"len after\", len_after)\n",
    "    \n",
    "    if len_before != len_after:\n",
    "        remove_leaf_node_syn(G)\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_hum_filtered = remove_leaf_nodes(G_hum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_syn_filtered = remove_leaf_node_syn(G_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_nodes =[node for node in list(G_syn.nodes) if G_syn.out_degree(node) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(leaf_nodes).intersection(set(synset_human.keys()))), len(leaf_nodes), len(synset_human.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_leaf_nodes(G, orig_node, parents = None, k=4, siblings_ordered=defaultdict(list)):\n",
    "    # if len(siblings_ordered[orig_node]) >= k:\n",
    "    #     print(\"returning top\")\n",
    "    #     return siblings_ordered[orig_node][:k]\n",
    "    # Get the parent node\n",
    "    if parents is None:\n",
    "        #print(\"parents is none\")\n",
    "        parents = list(G.predecessors(orig_node))\n",
    "        if len(parents) == 0:\n",
    "            #print(\"NO more parents\")\n",
    "            return None\n",
    "   # print(f\"Siblings ordered at this level:\", '\\n', f\"{[synset_human_complete[sibling] for sibling in siblings_ordered[orig_node]]}\")\n",
    "    #print(f\"current parents are: {[synset_human_complete[parent] for parent in parents]}\")\n",
    "    # Get all direct sibling leaf nodes\n",
    "    curr_siblings = []\n",
    "    for parent in parents:\n",
    "        #print(f\"Searching for Parent {synset_human_complete[parent]}:\", '\\n')\n",
    "        leaves_of_parent = [n for n in nx.dfs_preorder_nodes(G, parent) if G.out_degree(n) == 0 and n != orig_node and n not in siblings_ordered[orig_node]]\n",
    "        #print(f\"Leaves of Parent {synset_human_complete[parent]} are:\", '\\n')\n",
    "        #print(f\"{[synset_human_complete[leaf] for leaf in leaves_of_parent]}\")\n",
    "        curr_siblings.extend(leaves_of_parent)\n",
    "    #print(orig_node, curr_siblings)\n",
    "    #print(f\"Curr Siblings:\", '\\n', f\"{[synset_human_complete[sibling] for sibling in curr_siblings]}\")\n",
    "    distances = {}\n",
    "    for sibling in curr_siblings:\n",
    "        distances[sibling] = nx.shortest_path_length(G.to_undirected(as_view=True), orig_node, sibling)\n",
    "    \n",
    "    # Sort the siblings by distance and return the closest k\n",
    "    closest = sorted(distances, key=distances.get)[:k]\n",
    "    #print(f\"Curr Siblings sorted:\", '\\n', f\"{[synset_human_complete[sibling] for sibling in curr_siblings]}\")\n",
    "\n",
    "    siblings_ordered[orig_node].extend(closest)\n",
    "    #print(f\"Siblings ordered at this level:\", '\\n', f\"{[synset_human_complete[sibling] for sibling in siblings_ordered[orig_node]]}\")\n",
    "    \n",
    "    if len(siblings_ordered[orig_node]) >= k:\n",
    "        #print(\" len is greater than k\")\n",
    "        siblings_ordered[orig_node] = siblings_ordered[orig_node][:k]\n",
    "        #print(f\"returning {siblings_ordered[orig_node][:k]}\")\n",
    "        return None #siblings_ordered[orig_node][:k]\n",
    "    \n",
    "    else:\n",
    "        #print(\"exploring parents of parents\")\n",
    "        # If there are less than k siblings, go up to the parent's parent and try again\n",
    "        # get parents of parents\n",
    "        parents_of_parents = []\n",
    "        for parent in parents:\n",
    "            parents_of_parents.extend(list(G.predecessors(parent)))\n",
    "        \n",
    "        x = closest_leaf_nodes(G, orig_node, parents_of_parents, k, siblings_ordered)\n",
    "\n",
    "        return \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_leaf_nodes(G, orig_node, parents = None, k=4, siblings_ordered=defaultdict(list)):\n",
    "    if parents is None:\n",
    "        parents = list(G.predecessors(orig_node))\n",
    "        if len(parents) == 0:\n",
    "            return None\n",
    "    curr_siblings = []\n",
    "    for parent in parents:\n",
    "        leaves_of_parent = [n for n in nx.dfs_preorder_nodes(G, parent) if G.out_degree(n) == 0 and n != orig_node and n not in siblings_ordered[orig_node]]\n",
    "        curr_siblings.extend(leaves_of_parent)\n",
    "    distances = {}\n",
    "    for sibling in curr_siblings:\n",
    "        distances[sibling] = nx.shortest_path_length(G.to_undirected(as_view=True), orig_node, sibling)\n",
    " \n",
    "    closest = sorted(distances, key=distances.get)[:k]\n",
    " \n",
    "    siblings_ordered[orig_node].extend(closest)\n",
    "\n",
    "\n",
    "    if len(siblings_ordered[orig_node]) >= k:\n",
    "        siblings_ordered[orig_node] = siblings_ordered[orig_node][:k]\n",
    "        return None #siblings_ordered[orig_node][:k]\n",
    "    \n",
    "    else:\n",
    "\n",
    "        parents_of_parents = []\n",
    "        for parent in parents:\n",
    "            parents_of_parents.extend(list(G.predecessors(parent)))\n",
    "        \n",
    "        x = closest_leaf_nodes(G, orig_node, parents_of_parents, k, siblings_ordered)\n",
    "        return \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siblings_ordered = defaultdict(list)\n",
    "closest_leaf_nodes(G_syn_filtered, 'n01484850', k=4, siblings_ordered=siblings_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(siblings_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in siblings_ordered['n01484850']:\n",
    "    print(i)\n",
    "    print(synset_human_complete[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siblings_ordered = defaultdict(list)\n",
    "for i, node in enumerate(synset_human.keys(), 0):\n",
    "\n",
    "    closest_leaf_nodes(G_syn_filtered, node, k=4, siblings_ordered=siblings_ordered)\n",
    "    print(\"Node:\", synset_human_complete[node], node)\n",
    "    for sibling in siblings_ordered[node]:\n",
    "        print(\"Sibling:\", synset_human_complete[sibling])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the siblings_ordered dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in x:\n",
    "    print(synset_human_complete[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siblings_hum = {}\n",
    "for key, value in siblings_ordered.items():\n",
    "    siblings_hum[synset_human_complete[key]] = [synset_human_complete[i] for i in value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invert the dict index_synset to synset_index\n",
    "synset_index = {v: k for k, v in index_synset.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siblings_idx = {}\n",
    "for key, value in siblings_ordered.items():\n",
    "    siblings_idx[synset_index[key]] = [synset_index[i] for i in value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/image_idx_to_tgt_class_closest_5.yaml', 'w') as file:\n",
    "    documents = yaml.dump(dict(siblings_ordered), file)\n",
    "\n",
    "\n",
    "with open('data/image_idx_to_tgt_class_closest_5_human.yaml', 'w') as file:\n",
    "\n",
    "    documents = yaml.dump(dict(siblings_hum), file)\n",
    "\n",
    "with open('data/image_idx_to_tgt_class_closest_5_idx.yaml', 'w') as file:\n",
    "    \n",
    "        documents = yaml.dump(dict(siblings_idx), file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data from artifact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('kifarid/cdiff/run-nfw1b6uy-dvce_video:v4', type='run_table')\n",
    "df = pd.DataFrame(data=artifact.get(\"dvce_video\").data, columns=artifact.get(\"dvce_video\").columns)\n",
    "memory_usage = df.memory_usage(deep=True).sum()\n",
    "print(f\"Memory usage of dataframe is {memory_usage/1e6} MB\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the tgt_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "with open('data/synset_closest_idx.yaml', 'r') as file:\n",
    "    synset_closest_idx = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "data_path = '/misc/scratchSSD2/datasets/ILSVRC2012/val'\n",
    "out_size = 256\n",
    "transform_list = [\n",
    "    transforms.Resize((out_size,out_size)),\n",
    "    transforms.ToTensor()\n",
    "]\n",
    "transform = transforms.Compose(transform_list)\n",
    "dataset = datasets.ImageFolder(data_path,  transform=transform)\n",
    "\n",
    "idx_image_to_tgt_class = {}\n",
    "for i in range(len(dataset)):\n",
    "    img, label = dataset[i]\n",
    "    #print(synset_closest_idx[label], random.choice(synset_closest_idx[label]))\n",
    "    idx_image_to_tgt_class[i] = random.choice(synset_closest_idx[label])\n",
    "    if i%100==0:\n",
    "        print(f\"current image index: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert default dict to dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/image_idx_to_tgt_class.yaml', 'w') as file:\n",
    "    documents = yaml.dump(dict(idx_image_to_tgt_class), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the new Imagenet wrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/image_idx_to_tgt_class_closest_5.yaml', 'r') as file:\n",
    "    image_idx_to_tgt_class_closest_5 = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.imagenet_classnames import name_map, folder_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNet(datasets.ImageFolder):\n",
    "    classes = [name_map[i] for i in range(1000)]\n",
    "    name_map = name_map\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            root:str, \n",
    "            split:str=\"val\", \n",
    "            transform=None, \n",
    "            target_transform=None, \n",
    "            class_idcs=None, \n",
    "            start_sample: int = 0, \n",
    "            end_sample: int = 50000//1000,\n",
    "            return_tgt_cls: bool = False,\n",
    "            idx_to_tgt_cls_path = None, \n",
    "            **kwargs\n",
    "    ):\n",
    "        _ = kwargs  # Just for consistency with other datasets.\n",
    "        assert split in [\"train\", \"val\"]\n",
    "        assert start_sample < end_sample and start_sample >= 0 and end_sample <= 50000//1000\n",
    "        path = root if root[-3:] == \"val\" or root[-5:] == \"train\" else os.path.join(root, split)\n",
    "        super().__init__(path, transform=transform, target_transform=target_transform)\n",
    "        \n",
    "        with open(idx_to_tgt_cls_path, 'r') as file:\n",
    "            idx_to_tgt_cls = yaml.safe_load(file)\n",
    "            if isinstance(idx_to_tgt_cls, dict):\n",
    "                idx_to_tgt_cls = [idx_to_tgt_cls[i] for i in range(len(idx_to_tgt_cls))]\n",
    "        self.idx_to_tgt_cls = idx_to_tgt_cls\n",
    "\n",
    "        self.return_tgt_cls = return_tgt_cls\n",
    "\n",
    "        if class_idcs is not None:\n",
    "            class_idcs = list(sorted(class_idcs))\n",
    "            tgt_to_tgt_map = {c: i for i, c in enumerate(class_idcs)}\n",
    "            self.classes = [self.classes[c] for c in class_idcs]\n",
    "            samples = []\n",
    "            idx_to_tgt_cls = []\n",
    "            for i, (p, t) in enumerate(self.samples):\n",
    "                if t in tgt_to_tgt_map:\n",
    "                    samples.append((p, tgt_to_tgt_map[t]))\n",
    "                    idx_to_tgt_cls.append(self.idx_to_tgt_cls[i])\n",
    "            \n",
    "            self.idx_to_tgt_cls = idx_to_tgt_cls\n",
    "            #self.samples = [(p, tgt_to_tgt_map[t]) for i, (p, t) in enumerate(self.samples) if t in tgt_to_tgt_map]\n",
    "            self.class_to_idx = {k: tgt_to_tgt_map[v] for k, v in self.class_to_idx.items() if v in tgt_to_tgt_map}\n",
    "\n",
    "        if \"val\" == split: # reorder\n",
    "            new_samples = []\n",
    "            idx_to_tgt_cls = []\n",
    "            for idx in range(50000//1000):\n",
    "                new_samples.extend(self.samples[idx::50000//1000])\n",
    "                idx_to_tgt_cls.extend(self.idx_to_tgt_cls[idx::50000//1000])\n",
    "            self.samples = new_samples[start_sample*1000:end_sample*1000]\n",
    "            self.idx_to_tgt_cls = idx_to_tgt_cls[start_sample*1000:end_sample*1000]\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.class_labels = {i: folder_label_map[folder] for i, folder in enumerate(self.classes)}\n",
    "        self.targets = np.array(self.samples)[:, 1]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = super().__getitem__(index)\n",
    "        if self.return_tgt_cls:\n",
    "            return *sample, self.idx_to_tgt_cls[index]\n",
    "        else:\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx_to_tgt_class_closest_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#convert dict to list \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m image_idx_to_tgt_class_closest_5_list \u001b[39m=\u001b[39m [ image_idx_to_tgt_class_closest_5[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(image_idx_to_tgt_class_closest_5))]\n",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#convert dict to list \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m image_idx_to_tgt_class_closest_5_list \u001b[39m=\u001b[39m [ image_idx_to_tgt_class_closest_5[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(image_idx_to_tgt_class_closest_5))]\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#convert dict to list \n",
    "image_idx_to_tgt_class_closest_5_list = [ image_idx_to_tgt_class_closest_5[i] for i in range(len(image_idx_to_tgt_class_closest_5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImageNet('/misc/scratchSSD2/datasets/ILSVRC2012', idx_to_tgt_cls_path='data/image_idx_to_tgt.yaml', return_tgt_cls = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " data_loader = torch.utils.data.DataLoader(ds, batch_size=2, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.utils.data._utils.collate.default_collate(batch)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.classes[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[21][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.class_labels[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.classes[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_size = 256\n",
    "transform_list = [\n",
    "    transforms.Resize((out_size, out_size)),\n",
    "    transforms.ToTensor()\n",
    "]\n",
    "transform = transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImageNet('/misc/scratchSSD2/datasets/ILSVRC2012', split=\"val\", return_tgt_cls = True, idx_to_tgt_cls=image_idx_to_tgt_class_closest_5_list, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New cone projection approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image tench_eaten\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "path = 'tench_eaten.png'\n",
    "img = Image.open(path)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cone_project_chuncked(grad_temp_1, grad_temp_2, deg, chunk_size = 2):\n",
    "    \"\"\"\n",
    "    grad_temp_1: gradient of the loss w.r.t. the robust/classifier free\n",
    "    grad_temp_2: gradient of the loss w.r.t. the non-robust\n",
    "    projecting the robust/CF onto the non-robust\n",
    "    \"\"\"\n",
    "    orig_shp = (grad_temp_1.shape[0], 3, int((grad_temp_1.shape[-1]//3)**(1/2) ), int((grad_temp_1.shape[-1]//3)**(1/2) ))\n",
    "    print(orig_shp)\n",
    "    grad_temp_1_chuncked = grad_temp_1.view(*orig_shp) \\\n",
    "    .unfold(2, chunck_size, chunck_size) \\\n",
    "    .unfold(3, chunck_size, chunck_size) \\\n",
    "    .permute(0, 1, 4, 5, 2, 3) \\\n",
    "    .reshape(orig_shp[0], -1, orig_shp[-2]//chunck_size, orig_shp[-1]//chunck_size) \\\n",
    "    .permute(0, 2, 3, 1)\n",
    "    \n",
    "    grad_temp_2_chuncked = grad_temp_2.view(*orig_shp) \\\n",
    "    .unfold(2, chunck_size, chunck_size) \\\n",
    "    .unfold(3, chunck_size, chunck_size) \\\n",
    "    .permute(0, 1, 4, 5, 2, 3) \\\n",
    "    .reshape(orig_shp[0], -1, orig_shp[-2]//chunck_size, orig_shp[-1]//chunck_size) \\\n",
    "    .permute(0, 2, 3, 1)\n",
    "   \n",
    "    print(grad_temp_1_chuncked.shape, grad_temp_2_chuncked.shape)\n",
    "    angles_before_chuncked = torch.acos((grad_temp_1_chuncked * grad_temp_2_chuncked).sum(-1) / (grad_temp_1_chuncked.norm(p=2, dim=-1) * grad_temp_2_chuncked.norm(p=2, dim=-1)))\n",
    "    #print('angle before', angles_before_chuncked)\n",
    "    grad_temp_2_chuncked_norm = grad_temp_2_chuncked / grad_temp_2_chuncked.norm(p=2, dim=-1).view(grad_temp_1_chuncked.shape[0], grad_temp_1_chuncked.shape[1], grad_temp_1_chuncked.shape[1], -1)\n",
    "    #print(f\" norm {grad_temp_2_chuncked_norm.norm(p=2, dim=-1) ** 2}\")\n",
    "    grad_temp_1_chuncked = grad_temp_1_chuncked - ((grad_temp_1_chuncked * grad_temp_2_chuncked_norm).sum(-1) / (grad_temp_2_chuncked_norm.norm(p=2, dim=-1) ** 2)).view(\n",
    "         grad_temp_1_chuncked.shape[0], grad_temp_1_chuncked.shape[1], grad_temp_1_chuncked.shape[1], -1) * grad_temp_2_chuncked_norm\n",
    "\n",
    "    grad_temp_1_chuncked_norm = grad_temp_1_chuncked / grad_temp_1_chuncked.norm(p=2, dim=-1).view(grad_temp_1_chuncked.shape[0], grad_temp_1_chuncked.shape[1], grad_temp_1_chuncked.shape[1], -1)\n",
    "    radians = torch.tensor([deg], device=grad_temp_1_chuncked.device).deg2rad()\n",
    "    cone_projection = grad_temp_2_chuncked.norm(p=2, dim=-1).unsqueeze(-1) * grad_temp_1_chuncked_norm * torch.tan(radians) + grad_temp_2_chuncked\n",
    "\n",
    "    # second classifier is a non-robust one -\n",
    "    # unless we are less than 45 degrees away - don't cone project\n",
    "    #print(\" ratio of dimensions that are cone projected: \", (angles_before > radians).float().mean())\n",
    "    #print(\"angle before\", angles_before.mean(), angles_before.std(), angles_before.min(), angles_before.max())\n",
    "    #print(\"radians\", radians)\n",
    "    print(grad_temp_2_chuncked)\n",
    "\n",
    "    grad_temp_chuncked = grad_temp_2_chuncked.clone()\n",
    "    print(angles_before_chuncked > radians, grad_temp_1_chuncked.shape)\n",
    "    grad_temp_chuncked[angles_before_chuncked > radians] = grad_temp_1_chuncked[angles_before_chuncked > radians] #cone_projection[angles_before_chuncked > radians]\n",
    "    print(grad_temp_chuncked.shape)\n",
    "\n",
    "    \n",
    "\n",
    "    grad_temp = grad_temp_chuncked.permute(0, 3, 1, 2) \\\n",
    "    .reshape(orig_shp[0], orig_shp[1], \n",
    "    chunck_size, chunck_size,\n",
    "    grad_temp_1_chuncked.shape[1], grad_temp_1_chuncked\n",
    "    .shape[2]) \\\n",
    "    .permute(0, 1, 4, 2, 5, 3) \\\n",
    "    .reshape(*(orig_shp))\n",
    "     \n",
    "    print(angles_before_chuncked.shape)\n",
    "\n",
    "    return grad_temp, angles_before_chuncked > radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_1 = torch.rand(1, 3, 4, 4).float()\n",
    "input_tensor_2 = torch.rand(1, 3, 4, 4).float()\n",
    "cone_project_chuncked(input_tensor_1.view(1, -1), input_tensor_2.view(1, -1), 45., chunk_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "ldm"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
