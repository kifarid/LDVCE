{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/home/argusm/lang/')\n",
    "from LDVCE.data.imagenet_classnames import name_map\n",
    "\n",
    "\n",
    "class CFDataset():\n",
    "    def __init__(self, path, idx_to_tgt=\"/home/argusm/lang/LDVCE/data/image_idx_to_tgt.yaml\"):\n",
    "        self.images = []\n",
    "        self.path = path\n",
    "        for bucket_folder in sorted(glob.glob(self.path + \"/bucket*\")):\n",
    "            for original, counterfactual in zip(sorted(glob.glob(bucket_folder + \"/original/*.png\")), sorted(glob.glob(bucket_folder + \"/counterfactual/*.png\"))):\n",
    "                self.images.append((original, counterfactual, os.path.join(bucket_folder, os.path.basename(original).replace(\"png\", \"pth\"))))\n",
    "        imagenet_mean = (0.485, 0.456, 0.406)\n",
    "        iamgenet_std = (0.229, 0.224, 0.225)\n",
    "        self.transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((256, 256)),\n",
    "                torchvision.transforms.CenterCrop((224, 224)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=imagenet_mean, std=iamgenet_std),\n",
    "            ]\n",
    "        )\n",
    "        with open(idx_to_tgt, 'r') as file:\n",
    "            idx_to_tgt_cls = yaml.safe_load(file)\n",
    "            if isinstance(idx_to_tgt_cls, dict):\n",
    "                idx_to_tgt_cls = [idx_to_tgt_cls[i]\n",
    "        for i in range(len(idx_to_tgt_cls))]\n",
    "            self.idx_to_tgt_cls = idx_to_tgt_cls\n",
    "        idx_to_tgt_cls = []\n",
    "        for idx in range(50000//1000):\n",
    "            idx_to_tgt_cls.extend(self.idx_to_tgt_cls[idx::50000//1000])\n",
    "        self.idx_to_tgt_cls = idx_to_tgt_cls\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        original_path, counterfactual_path, pth_file = self.images[idx]\n",
    "        original = self.load_img(original_path)\n",
    "        counterfactual = self.load_img(counterfactual_path)\n",
    "        # data = torch.load(pth_file, map_location=\"cpu\")\n",
    "        # counterfactual = data[\"gen_image\"]\n",
    "        return original, idx%1000, counterfactual, self.idx_to_tgt_cls[idx]\n",
    "    \n",
    "    def load_img(self, path):\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        return self.transform(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d503bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "method, path = \"LDCE\", \"/misc/lmbraid21/faridk/LDCE_w382_cc23\"\n",
    "#method, path = \"SVCE\", \"/misc/lmbraid21/faridk/ImageNetSVCEs_robustOnly\"\n",
    "#method, path = \"DVCE\", \"/misc/lmbraid21/faridk/ImageNetDVCEs_\"\n",
    "\n",
    "dataset = CFDataset(path)\n",
    "print(len(dataset))\n",
    "batch_size = 12\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72eb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import timm\n",
    "device = torch.device('cuda')\n",
    "\n",
    "models = [\"pytorch10_resnet50\",\"pytorch10_resnet18\",\"pytorch10_resnet101\",\n",
    "          \"pytorch10_inception_v3\", \"pytorch10_resnext50_32x4d\",\n",
    "          \"timm_resnet50\",  \"timm_resnet101\"] #\"timm_resnet18\"\n",
    "\n",
    "def get_model(name=\"pytorch10_resnet50\"):\n",
    "    if name == \"pytorch10_resnet50\":\n",
    "        return torchvision.models.resnet50(pretrained=True)\n",
    "    if name == \"pytorch10_resnet18\":\n",
    "        return torchvision.models.resnet18(pretrained=True)\n",
    "    if name == \"pytorch10_resnet101\":\n",
    "        return torchvision.models.resnet101(pretrained=True)\n",
    "    if name == \"pytorch10_inception_v3\":\n",
    "        return torchvision.models.inception_v3(pretrained=True)\n",
    "    if name == \"pytorch10_resnext50_32x4d\":\n",
    "        return torchvision.models.resnext50_32x4d(pretrained=True)\n",
    "    if name == \"timm_resnet50\":\n",
    "        return timm.create_model('resnet50', pretrained=True)\n",
    "    if name == \"timm_resnet18\":\n",
    "        return timm.create_model('resnet18', pretrained=True)\n",
    "    if name == \"timm_resnet101\":\n",
    "        return timm.create_model('resnet101', pretrained=True)\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb8813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(name):\n",
    "    model = get_model(name)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    loader = data.DataLoader(dataset, batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=num_workers, pin_memory=True)\n",
    "    orig_list = []  # original predictions\n",
    "    label_list = []  # original gt labels\n",
    "    counter_list = []  # counterfactual predictions\n",
    "    target_list = []  # target labels\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for orig, label, counter, target in tqdm(loader):\n",
    "            orig = orig.to(device, dtype=torch.float)\n",
    "            counter = counter.to(device, dtype=torch.float)\n",
    "            label_list.append(label)\n",
    "            target_list.append(target)\n",
    "            orig_list.append(model(orig).argmax(1).cpu().numpy())\n",
    "            counter_list.append(model(counter).argmax(1).cpu().numpy())\n",
    "\n",
    "    orig_list = np.concatenate(orig_list)\n",
    "    label_list = np.concatenate(label_list)\n",
    "    counter_list = np.concatenate(counter_list)\n",
    "    target_list = np.concatenate(target_list)\n",
    "    np.savez(f\"{method}_{name}.npz\", orig_pred=orig_list, orig_label=label_list,\n",
    "             counter_pred=counter_list,counter_label=target_list)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes long\n",
    "for model_name in models:\n",
    "    print(\"evaluatin\", model_name)\n",
    "    eval_model(model_name)\n",
    "    \n",
    "#eval_model(\"pytorch10_resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.load(f\"{method}_pytorch10_resnet50.npz\")\n",
    "orig_pred = tmp[\"orig_pred\"]\n",
    "orig_label = tmp[\"orig_label\"]\n",
    "counter_pred = tmp[\"counter_pred\"]\n",
    "counter_label = tmp[\"counter_label\"]\n",
    "\n",
    "np.mean(counter_pred == counter_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def eval_classes(class_file):\n",
    "    tmp = np.load(class_file)\n",
    "    orig_pred = tmp[\"orig_pred\"]\n",
    "    orig_label = tmp[\"orig_label\"]\n",
    "    counter_pred = tmp[\"counter_pred\"]\n",
    "    counter_label = tmp[\"counter_label\"]\n",
    "    return orig_pred, orig_label, counter_pred, counter_label\n",
    "\n",
    "def get_runs():\n",
    "    for x in sorted(os.listdir()):\n",
    "        if (\".npz\" not in x) or (x == \"class_labels.npz\"):\n",
    "            continue\n",
    "        yield x\n",
    "\n",
    "tmp = {}\n",
    "for method in (\"LDCE\",\"SVCE\", \"DVCE\"):\n",
    "    tmp[method] = {}\n",
    "    base_orig_pred, base_orig_label, base_counter_pred, base_counter_label = eval_classes(f\"{method}_pytorch10_resnet50.npz\")\n",
    "    for model in models:\n",
    "        x = f\"{method}_{model}.npz\"\n",
    "        orig_pred, orig_label, counter_pred, counter_label = eval_classes(x)\n",
    "        fr = np.mean(counter_pred == counter_label)\n",
    "        cr = np.mean(counter_pred != orig_pred)\n",
    "        cf = np.mean(base_counter_pred == counter_pred)\n",
    "        #rows.append((method, model, fr, cr))\n",
    "        tmp[method][model] = dict(fr=fr,cr=cr, cf=cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f31213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def short(x):\n",
    "    return x.replace(\"pytorch10_\",\"\").replace(\"resnet\",\"rn\").replace(\"inception\",\"in\").replace(\"resnext50_32x4d\",\"rNeXt\").replace(\"timm_\",\"t_\")\n",
    "print(\"    \", \"\\t\".join([short(x) for x in models]))\n",
    "for method in (\"SVCE\", \"DVCE\",\"LDCE\"):\n",
    "    print(method, \"\\t\".join(str(tmp[method][model][\"cf\"]) for model in models))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e23d9a",
   "metadata": {},
   "source": [
    "for x in get_runs():\n",
    "    print(x)\n",
    "    m = x.split(\"_\")[0]\n",
    "    \n",
    "    orig_pred, orig_label, counter_pred, counter_label = eval_classes(x)\n",
    "    print(\"Change Rate:\", np.mean(counter_pred != orig_pred).round(12))\n",
    "    print(\"Flip Rate*: \", np.mean(counter_pred == counter_label).round(12))\n",
    "    #print(\"Same Rate: \", np.mean(counter_pred == orig_label).round(3))\n",
    "    #print(\"Start Rate: \", np.mean(orig_pred == orig_label).round(3))\n",
    "    \n",
    "    #selection = orig_pred == orig_label\n",
    "    #print(\"Change Rate$:\", np.mean(counter_pred[selection] != orig_pred[selection]).round(3))\n",
    "    #print(\"Flip Rate$: \", np.mean(counter_pred[selection] == counter_label[selection]).round(3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975584f",
   "metadata": {},
   "source": [
    "base_orig_pred, base_orig_label, base_counter_pred, base_counter_label = eval_classes(\"pytorch10_resnet50.npz\")\n",
    "\n",
    "for x in get_runs():\n",
    "    print(x)\n",
    "    orig_pred, orig_label, counter_pred, counter_label = eval_classes(x)\n",
    "    print(\"corr pred orig\", np.mean(base_orig_pred == orig_pred))\n",
    "    print(\"corr pred cf  \", np.mean(base_counter_pred == counter_pred))\n",
    "    select = base_orig_pred == orig_pred\n",
    "    print(\"corr pred cf* \", np.mean(base_counter_pred[select] == counter_pred[select]).round(4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e888ad",
   "metadata": {},
   "source": [
    "### Check if pytorch and timm resnet18 are the same (yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3772fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_pred, _, counter_pred, _ = eval_classes(\"pytorch10_resnet18.npz\")\n",
    "orig_pred2, _, counter_pred2, _ = eval_classes(\"timm_resnet18.npz\")\n",
    "print(np.mean(orig_pred==orig_pred2))\n",
    "print(np.mean(counter_pred==counter_pred2))\n",
    "\n",
    "pytorch_18 = get_model(name=\"pytorch10_resnet18\")\n",
    "timm_18 = get_model(name=\"pytorch10_resnet18\")\n",
    "\n",
    "def compareModelWeights(model_a, model_b):\n",
    "    module_a = model_a._modules\n",
    "    module_b = model_b._modules\n",
    "    if len(list(module_a.keys())) != len(list(module_b.keys())):\n",
    "        return False\n",
    "    a_modules_names = list(module_a.keys())\n",
    "    b_modules_names = list(module_b.keys())\n",
    "    for i in range(len(a_modules_names)):\n",
    "        layer_name_a = a_modules_names[i]\n",
    "        layer_name_b = b_modules_names[i]\n",
    "        if layer_name_a != layer_name_b:\n",
    "            return False\n",
    "        layer_a = module_a[layer_name_a]\n",
    "        layer_b = module_b[layer_name_b]\n",
    "        if (\n",
    "            (type(layer_a) == nn.Module) or (type(layer_b) == nn.Module) or\n",
    "            (type(layer_a) == nn.Sequential) or (type(layer_b) == nn.Sequential)\n",
    "            ):\n",
    "            if not compareModelWeights(layer_a, layer_b):\n",
    "                return False\n",
    "        if hasattr(layer_a, 'weight') and hasattr(layer_b, 'weight'):\n",
    "            if not torch.equal(layer_a.weight.data, layer_b.weight.data):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "print(\"same:\",compareModelWeights(pytorch_18,timm_18))\n",
    "del pytorch_18\n",
    "del timm_18"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
