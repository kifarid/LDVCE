
# #create a config yaml file for training with pytorch lightning with the following arguments
# diffusion_path,
# num_classes,
# ckpt_path=None,
# pool='attention',
# label_key=None,
# diffusion_ckpt_path=None,
# scheduler_config=None,
# weight_decay=1.e-2,
# log_steps=10,
# monitor='val/loss',


model:
  base_learning_rate: 0.00003
  target: ldm.models.diffusion.classifier.NoisyLatentImageClassifier
  params:
    diffusion_path: configs/latent-diffusion/cin256-v2.yaml #models/ldm/cin256-v2/config.yaml
    num_classes: 101
    ckpt_path:
    pool: attention
    label_key: class_label
    backbone: resnet18
    diffusion_ckpt_path: models/ldm/cin256-v2/model.ckpt
    monitor: val/loss
    log_steps: 10

data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 32
    num_workers: 0
    wrap: false
    train:
      target: ldm.data.caltech.Caltech101
      params:
        root: "./data_caltech"
        download: true
        train: true
        size: 256

    validation:
      target: ldm.data.caltech.Caltech101
      params:
        root: "./data_caltech"
        download: true
        train: false
        size: 256
lightning:

  logger:
    params:
      entity: kifarid
      project: cdiff

  trainer:
    accumulate_grad_batches: 1
    #devices: 0,
    #accelerator: "gpu"
    limit_val_batches: 1
